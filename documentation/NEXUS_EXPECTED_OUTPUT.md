# Nexus Bootstrap - Expected Output

This document shows what users will see when they run the bootstrap script.

## Running the Script

```powershell
PS> .\scripts\bootstrap-nexus.ps1
```

## Expected Console Output

```
ðŸš€ Nexus + InstallSure Bootstrap Starting...
=============================================

ðŸ“¦ Configuration:
   Chat Model: qwen2.5-coder:7b
   Embed Model: nomic-embed-text

ðŸ”§ Step 1: Checking Ollama...
   âœ… Ollama already installed
   Starting Ollama service...
   Pulling models...
pulling manifest
pulling 8934d96d3f08... 100% â–•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– 4.7 GB
pulling 2490e7468436... 100% â–•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  109 B
pulling eb4ce6d81186... 100% â–•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  11 KB
pulling 7f1cf8827567... 100% â–•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  487 B
verifying sha256 digest
writing manifest
success
   âœ… Models ready

ðŸ”§ Step 2: Creating project structure...
   âœ… Directories created

ðŸ”§ Step 3: Creating system prompt...
   âœ… System prompt created

ðŸ”§ Step 4: Creating Python requirements...
   âœ… Requirements file created

ðŸ”§ Step 5: Creating sample library manifest...
   âœ… Library manifest created

ðŸ”§ Step 6: Creating FastAPI server...
   âœ… FastAPI server created

ðŸ”§ Step 7: Installing Python dependencies...
   âœ… Dependencies installed

ðŸ”§ Step 8: Starting FastAPI server...
   âœ… Server started on http://127.0.0.1:5323

ðŸ”§ Step 9: Running demo...
   Verifying LLM and KB...
   Running daily learning...
   Adding memory...
   Attempting library ingest...
   Running full demo...

=============================================
âœ… NEXUS + INSTALLSURE BOOTSTRAP COMPLETE!
=============================================

ðŸ“Š Configuration Summary:
   LLM Base:  http://localhost:11434/v1
   Model:     qwen2.5-coder:7b
   Embeds:    nomic-embed-text
   KB Size:   23
   Learn Add: 15
   Library:   skipped

ðŸ“ Output Files:
   Daily brief: nexus/data/daily_brief.md
   Demo receipt: nexus/data/demo_receipt.json

ðŸ”§ Cursor/Copilot OpenAI-compatible Configuration:
   Base URL: http://localhost:11434/v1
   API Key:  ollama
   Model:    qwen2.5-coder:7b

=============================================

ðŸ“š What to do next:

1. Edit sample-library.manifest.json with real URLs, then re-run:
   Invoke-RestMethod http://127.0.0.1:5323/library/ingest -Method POST

2. Add a lecture transcript to the KB:
   Invoke-RestMethod http://127.0.0.1:5323/youtube/add -Method POST `
     -ContentType "application/json" `
     -Body '{"url":"https://www.youtube.com/watch?v=YOUR_VIDEO"}'

3. Point Cursor (or VS Code + Copilot) to your local LLM:
   Provider: OpenAI-compatible
   Base URL: http://localhost:11434/v1
   API Key:  ollama
   Model:    qwen2.5-coder:7b

âœ¨ Done! Server is running at http://127.0.0.1:5323
=============================================
```

## Files Created After Running

```
External-Review-Repository/
â”œâ”€â”€ nexus/
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ daily_brief.md         # Daily learning summary
â”‚   â”‚   â””â”€â”€ demo_receipt.json      # Demo run results
â”‚   â”œâ”€â”€ memory/
â”‚   â”‚   â””â”€â”€ journal.jsonl          # Memory entries
â”‚   â”œâ”€â”€ chroma/                    # Vector database files
â”‚   â”œâ”€â”€ server.py                  # FastAPI application
â”‚   â””â”€â”€ requirements.txt           # Python dependencies
â”œâ”€â”€ prompts/
â”‚   â””â”€â”€ nexus.system.txt           # AI system prompt
â”œâ”€â”€ samples/                       # Empty, ready for samples
â”œâ”€â”€ frontend/public/library/       # Empty, ready for docs
â””â”€â”€ sample-library.manifest.json   # Library configuration
```

## Testing the API

### 1. Check Status
```powershell
PS> Invoke-RestMethod http://127.0.0.1:5323/verify

kb_size     : 23
llm_base    : http://localhost:11434/v1
model       : qwen2.5-coder:7b
embed_model : nomic-embed-text
```

### 2. View Daily Brief
```powershell
PS> Get-Content nexus/data/daily_brief.md

## HN
- Story 1: Title about AI advancement
- Story 2: New framework release
...

## arXiv
- Paper on neural networks
- Study on language models
...

## GitHub
- user/repo: Popular Python library for ML
- org/project: New web framework
...
```

### 3. Check Memory
```powershell
PS> Invoke-RestMethod http://127.0.0.1:5323/memory/dump

entries : 2
```

### 4. View Memory Journal
```powershell
PS> Get-Content nexus/memory/journal.jsonl

{"memory":"Tony prefers typed checklists and structured outputs.","tags":["tony","preference"]}
{"memory":"Remember: prefer unit-tested outputs, then code.","tags":["policy","tests-first"]}
```

## Success Indicators

âœ… Ollama is running
âœ… Models are downloaded
âœ… Python dependencies installed
âœ… FastAPI server started on port 5323
âœ… Knowledge base initialized with 8+ entries
âœ… Daily learning completed with 10+ new entries
âœ… Memory system working
âœ… All API endpoints responding
âœ… Files generated correctly

## Next Steps

1. **Customize models**: Edit `$env:OLLAMA_MODEL_CHAT` before running
2. **Add documents**: Edit `sample-library.manifest.json` with real URLs
3. **Index YouTube**: Use `/youtube/add` endpoint with real video URLs
4. **Configure IDE**: Point Cursor/Copilot to local Ollama
5. **Daily use**: Server auto-learns at 7 AM daily
6. **Memory**: Add important facts via `/memory/add`

## Troubleshooting

If you see errors, check:
- Ollama is installed and running
- Python 3.10+ is available
- Port 5323 is not in use
- Internet connection for downloads
- Sufficient disk space for models (~8 GB)

For more help, see:
- documentation/NEXUS_AI_GUIDE.md
- documentation/NEXUS_QUICK_REFERENCE.md
